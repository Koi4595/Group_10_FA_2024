{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0: Merge Dividend Yield Data with Company Data\n",
    "[This dataset](https://www.kaggle.com/datasets/patricklford/largest-companies-analysis-worldwide) provides around 10,000 records of the largest companies worldwide. For a job-seeker, Dividend Yield is a key metric to consider when evaluating a company. Dividend Yield is the ratio of the annual dividend per share to the current price per share. So if a job-seeker is offered shares as part of their compensation, they would want to know the Dividend Yield of the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/si618/lib/python3.12/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_df = pd.read_csv('Projectdata/Companies_ranked_by_Dividend_Yield.csv')\n",
    "company_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df = pd.read_csv('Projectdata/job_company_pair.csv')\n",
    "# randomly select 5 name from job_df\n",
    "job_df['name'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new df that only contains company name in job_df\n",
    "job_df_name = job_df['name'].unique()\n",
    "job_df_name = pd.DataFrame(job_df_name,columns=['company_name'])\n",
    "job_df_name.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the two dataset are from different sources, we will match the company names using following steps:\n",
    "1. Remove special characters and spaces from the company names in both datasets.\n",
    "2. Convert the company names to lowercase.\n",
    "3. Use the `fuzzywuzzy` library to match the company names.\n",
    "4. If the match score is above a certain threshold, we will consider the two company names to be the same. We will create a new column called `is_top` in the `job_df` dataset to store if there is a match in the `company_df` dataset.\n",
    "5. If `is_top` is False, check if the company name in the `job_df` dataset is a substring of any company name in the `company_df` dataset and vice versa. If it is, we will consider the two company names to be the same and change `is_top` to True.\n",
    "6. If `is_top` is True, we will merge the relevant columns from the `company_df` dataset to the `job_df` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_company_name(name):\n",
    "    \"\"\"\n",
    "    Clean company name by:\n",
    "    1. Removing special characters and spaces\n",
    "    2. Converting to lowercase\n",
    "    \"\"\"\n",
    "    # Convert to string in case of non-string input\n",
    "    name = str(name)\n",
    "    \n",
    "    # Remove special characters and convert to lowercase\n",
    "    cleaned_name = re.sub(r'[^a-zA-Z0-9]', '', name).lower()\n",
    "    \n",
    "    return cleaned_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_longest_substring(s1, s2):\n",
    "    \"\"\"\n",
    "    Find the longest consecutive substring between two strings\n",
    "    \"\"\"\n",
    "    # Remove non-alphanumeric characters\n",
    "    s1 = re.sub(r'[^a-z0-9]', '', s1)\n",
    "    s2 = re.sub(r'[^a-z0-9]', '', s2)\n",
    "    \n",
    "    # Find all consecutive substrings of at least 6 characters\n",
    "    for length in range(min(len(s1), len(s2)), 5, -1):\n",
    "        for i in range(len(s1) - length + 1):\n",
    "            substring = s1[i:i+length]\n",
    "            if substring in s2:\n",
    "                return substring\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_company_names(job_df, company_df, match_threshold=80):\n",
    "    \"\"\"\n",
    "    Match company names between job and company datasets\n",
    "    \n",
    "    Parameters:\n",
    "    - job_df: DataFrame with job listings\n",
    "    - company_df: DataFrame with company information\n",
    "    - match_threshold: Fuzzy matching threshold (default 80)\n",
    "    \n",
    "    Returns:\n",
    "    - Updated job_df with new columns\n",
    "    \"\"\"\n",
    "    # Create copies to avoid modifying original dataframes\n",
    "    job_df = job_df.copy()\n",
    "    company_df = company_df.copy()\n",
    "    \n",
    "    job_df['cleaned_company_name'] = job_df['company_name'].apply(clean_company_name)\n",
    "    company_df['cleaned_company_name'] = company_df['Name'].apply(clean_company_name)\n",
    "    \n",
    "    # Create a dictionary of company names for faster lookup\n",
    "    company_dict = {row['cleaned_company_name']: row for _, row in company_df.iterrows()}\n",
    "    \n",
    "    def find_best_match(job_company):\n",
    "        # Exact match\n",
    "        if job_company in company_dict:\n",
    "            return True, company_dict[job_company]\n",
    "        \n",
    "        # Fuzzy and substring matching\n",
    "        best_match = None\n",
    "        best_score = 0\n",
    "        \n",
    "        for company_name, company_info in company_dict.items():\n",
    "            # Fuzzy ratio match\n",
    "            ratio = fuzz.ratio(job_company, company_name)\n",
    "            \n",
    "            # Substring match bonus\n",
    "            substring_bonus = (job_company in company_name or company_name in job_company)\n",
    "            \n",
    "            # Calculate score with substring bonus\n",
    "            score = ratio + (20 if substring_bonus else 0)\n",
    "            \n",
    "            if score > best_score and score >= match_threshold:\n",
    "                best_score = score\n",
    "                best_match = company_info\n",
    "        \n",
    "        return best_match is not None, best_match\n",
    "    \n",
    "    # Vectorized matching\n",
    "    results = job_df['cleaned_company_name'].apply(find_best_match)\n",
    "    \n",
    "    # Update DataFrame\n",
    "    job_df['is_top'] = results.apply(lambda x: x[0])\n",
    "    \n",
    "    # Merge additional company information for matched companies\n",
    "    def merge_company_info(row, matched_result):\n",
    "        if matched_result[0]:\n",
    "            # Merge relevant columns from company_df\n",
    "            company_info = matched_result[1]\n",
    "            columns_to_merge = ['dividend_yield_ttm','price (GBP)']\n",
    "            for col in columns_to_merge:\n",
    "                if col in company_df.columns and col not in job_df.columns:\n",
    "                    row[col] = company_info[col]\n",
    "        return row\n",
    "    \n",
    "    # Apply merging\n",
    "    job_df = job_df.apply(lambda row: merge_company_info(row, \n",
    "                                       results.loc[row.name]), \n",
    "                           axis=1)\n",
    "    \n",
    "    # Optional: Drop the temporary cleaning column\n",
    "    \n",
    "    return job_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_job_df = match_company_names(job_df_name, company_df)\n",
    "matched_job_df.sort_values('is_top', ascending=False).head(5)\n",
    "matched_job_df.to_csv('Projectdata/matched_companies.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the matched job listings with the original job listings\n",
    "job_company_df = pd.read_csv('Projectdata/job_company_pair.csv')\n",
    "job_company_df['cleaned_company_name'] = job_company_df['name'].apply(clean_company_name)\n",
    "job_company_df = pd.merge(job_company_df, matched_job_df, how='left', on='cleaned_company_name')\n",
    "job_company_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_company_df.drop(columns=['cleaned_company_name','name'], inplace=True)\n",
    "job_company_df.to_csv('Projectdata/matched_job_company_pair.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data (80 points)\n",
    "\n",
    "1. Import the dataset you have chosen based on your earlier assignments.\n",
    "2. Clean your dataset, handling missing values, inconsistencies, and any other issues you encounter.  You should be able to reuse code from earlier work to help you do this, although you may need to make some modifications.\n",
    "3. Apply various preprocessing techniques such as feature scaling, one-hot encoding, handling categorical variables, and dimensionality reduction.\n",
    "4. Justify the preprocessing choices made, ensuring that they align with the analytical techniques you plan to use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_id                          0\n",
       "company_id                      0\n",
       "skill_abr                       0\n",
       "skill_name                      0\n",
       "industry_id                     0\n",
       "max_salary                  48190\n",
       "med_salary                 260360\n",
       "min_salary                  48190\n",
       "pay_period                      0\n",
       "industry_name                  41\n",
       "company_size                 5532\n",
       "country                         0\n",
       "employee_count                  0\n",
       "follower_count                  0\n",
       "employee_follower_ratio         4\n",
       "annual_min_salary               0\n",
       "annual_max_salary               0\n",
       "annual_med_salary               0\n",
       "skill_category                  0\n",
       "company_name                    0\n",
       "dividend_yield_ttm         170707\n",
       "is_top                          0\n",
       "price (GBP)                170707\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the matched job listings and check missing values\n",
    "job_company_df = pd.read_csv('Projectdata/matched_job_company_pair.csv')\n",
    "job_company_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`max_salary`, `min_salary` and `med_salary` all have missing values because they are not available for all job postings. Also, `pay_period` is inconsistent because for different posting it may have different pay period. In project part I, we converted all salaries into annual salaries, and filled missing (min, max) or median salary based on the other column(s). \n",
    "\n",
    "There might be a mismatch between `pay_period` here and the actual pay period. And that will cause the salary to be incorrect. So, we set $ 7540 as the threshold for annual salary. If the salary is below this threshold, we will consider it as incorrect and remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop max_salary, med_salary and min_salary columns\n",
    "job_company_df.drop(columns=['max_salary','med_salary','min_salary', 'pay_period'], inplace=True)\n",
    "\n",
    "# Keep only rows with annual_min_salary > 7540\n",
    "job_company_df = job_company_df[job_company_df['annual_min_salary'] > 7540]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop if industry_name is null, fill missing values in dividend_yield_ttm and price (GBP) with 0\n",
    "job_company_df.dropna(subset=['industry_name'], inplace=True)\n",
    "job_company_df.fillna({'dividend_yield_ttm': 0, 'price (GBP)': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values in employee_follower_ratio with 0\n",
    "job_company_df.fillna({'employee_follower_ratio': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>company_id</th>\n",
       "      <th>skill_abr</th>\n",
       "      <th>skill_name</th>\n",
       "      <th>industry_id</th>\n",
       "      <th>industry_name</th>\n",
       "      <th>company_size</th>\n",
       "      <th>country</th>\n",
       "      <th>employee_count</th>\n",
       "      <th>follower_count</th>\n",
       "      <th>employee_follower_ratio</th>\n",
       "      <th>annual_min_salary</th>\n",
       "      <th>annual_max_salary</th>\n",
       "      <th>annual_med_salary</th>\n",
       "      <th>skill_category</th>\n",
       "      <th>company_name</th>\n",
       "      <th>dividend_yield_ttm</th>\n",
       "      <th>is_top</th>\n",
       "      <th>price (GBP)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>299953</th>\n",
       "      <td>3904954875</td>\n",
       "      <td>14803700.0</td>\n",
       "      <td>IT</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>4</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GB</td>\n",
       "      <td>3</td>\n",
       "      <td>14294</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>190000.0</td>\n",
       "      <td>158000.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Orbit Recruitment Group</td>\n",
       "      <td>0.000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288074</th>\n",
       "      <td>3902866871</td>\n",
       "      <td>12907420.0</td>\n",
       "      <td>ENG</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>7</td>\n",
       "      <td>Semiconductor Manufacturing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>6</td>\n",
       "      <td>1417</td>\n",
       "      <td>0.004234</td>\n",
       "      <td>165000.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>168000.0</td>\n",
       "      <td>Technical &amp; Engineering</td>\n",
       "      <td>VivaHire</td>\n",
       "      <td>0.000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139156</th>\n",
       "      <td>3886217072</td>\n",
       "      <td>77586042.0</td>\n",
       "      <td>MRKT</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>17</td>\n",
       "      <td>Medical Equipment Manufacturing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>1162</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>Creative</td>\n",
       "      <td>Talient Solutions</td>\n",
       "      <td>118.475</td>\n",
       "      <td>True</td>\n",
       "      <td>20.39005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267131</th>\n",
       "      <td>3905257175</td>\n",
       "      <td>91652182.0</td>\n",
       "      <td>LGL</td>\n",
       "      <td>Legal</td>\n",
       "      <td>24</td>\n",
       "      <td>Computers and Electronics Manufacturing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>25</td>\n",
       "      <td>2983</td>\n",
       "      <td>0.008381</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>700000.0</td>\n",
       "      <td>244000.0</td>\n",
       "      <td>Legal &amp; Compliance</td>\n",
       "      <td>Haraka Headhunters</td>\n",
       "      <td>0.000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274563</th>\n",
       "      <td>3901350004</td>\n",
       "      <td>76345004.0</td>\n",
       "      <td>FIN</td>\n",
       "      <td>Finance</td>\n",
       "      <td>4</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>5</td>\n",
       "      <td>271</td>\n",
       "      <td>0.018450</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>56000.0</td>\n",
       "      <td>Finance</td>\n",
       "      <td>TaxPlanIQ (SaaS tax planning for accountants)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            job_id  company_id skill_abr              skill_name  industry_id  \\\n",
       "299953  3904954875  14803700.0        IT  Information Technology            4   \n",
       "288074  3902866871  12907420.0       ENG             Engineering            7   \n",
       "139156  3886217072  77586042.0      MRKT               Marketing           17   \n",
       "267131  3905257175  91652182.0       LGL                   Legal           24   \n",
       "274563  3901350004  76345004.0       FIN                 Finance            4   \n",
       "\n",
       "                                  industry_name  company_size country  \\\n",
       "299953                     Software Development           NaN      GB   \n",
       "288074              Semiconductor Manufacturing           NaN      US   \n",
       "139156          Medical Equipment Manufacturing           NaN      US   \n",
       "267131  Computers and Electronics Manufacturing           NaN      US   \n",
       "274563                     Software Development           NaN      US   \n",
       "\n",
       "        employee_count  follower_count  employee_follower_ratio  \\\n",
       "299953               3           14294                 0.000210   \n",
       "288074               6            1417                 0.004234   \n",
       "139156               1            1162                 0.000861   \n",
       "267131              25            2983                 0.008381   \n",
       "274563               5             271                 0.018450   \n",
       "\n",
       "        annual_min_salary  annual_max_salary  annual_med_salary  \\\n",
       "299953           150000.0           190000.0           158000.0   \n",
       "288074           165000.0           180000.0           168000.0   \n",
       "139156            50000.0            70000.0            54000.0   \n",
       "267131           130000.0           700000.0           244000.0   \n",
       "274563            50000.0            80000.0            56000.0   \n",
       "\n",
       "                 skill_category  \\\n",
       "299953                    Other   \n",
       "288074  Technical & Engineering   \n",
       "139156                 Creative   \n",
       "267131       Legal & Compliance   \n",
       "274563                  Finance   \n",
       "\n",
       "                                         company_name  dividend_yield_ttm  \\\n",
       "299953                       Orbit Recruitment Group                0.000   \n",
       "288074                                       VivaHire               0.000   \n",
       "139156                              Talient Solutions             118.475   \n",
       "267131                             Haraka Headhunters               0.000   \n",
       "274563  TaxPlanIQ (SaaS tax planning for accountants)               0.000   \n",
       "\n",
       "        is_top  price (GBP)  \n",
       "299953   False      0.00000  \n",
       "288074   False      0.00000  \n",
       "139156    True     20.39005  \n",
       "267131   False      0.00000  \n",
       "274563   False      0.00000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample 5 rows from missing company_size\n",
    "job_company_df[job_company_df['company_size'].isnull()].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see it's highly likely that a posting with a missing company_size is a posting from a recruiter. So we will check if the company itself's posting is in this dataset. We will check if there is another job with same skill_abr and annual_med_salary; if so, we will drop this row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows to drop: 4519\n"
     ]
    }
   ],
   "source": [
    "# Identify rows with missing company size\n",
    "missing_company_size = job_company_df[job_company_df['company_size'].isna()]\n",
    "\n",
    "# Create a list to store indices of rows to drop\n",
    "rows_to_drop = []\n",
    "\n",
    "# Iterate through rows with missing company size\n",
    "for idx, row in missing_company_size.iterrows():\n",
    "    # Find potential matching jobs based on skill_abr, industry_id, and annual_med_salary\n",
    "    matching_jobs = job_company_df[\n",
    "        (job_company_df['skill_abr'] == row['skill_abr']) & \n",
    "        (job_company_df['annual_med_salary'] == row['annual_med_salary']) & \n",
    "        (job_company_df['company_size'].notna())\n",
    "    ]\n",
    "    \n",
    "    # If a matching job exists, mark this row for dropping\n",
    "    if not matching_jobs.empty:\n",
    "        rows_to_drop.append(idx)\n",
    "\n",
    "print(f\"Rows to drop: {len(rows_to_drop)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_company_df.drop(index=rows_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For other missing values in company_size, fill with 0 since we assume they are small companies\n",
    "job_company_df.fillna({'company_size': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_id                     0\n",
       "company_id                 0\n",
       "skill_abr                  0\n",
       "skill_name                 0\n",
       "industry_id                0\n",
       "industry_name              0\n",
       "company_size               0\n",
       "country                    0\n",
       "employee_count             0\n",
       "follower_count             0\n",
       "employee_follower_ratio    0\n",
       "annual_min_salary          0\n",
       "annual_max_salary          0\n",
       "annual_med_salary          0\n",
       "skill_category             0\n",
       "company_name               0\n",
       "dividend_yield_ttm         0\n",
       "is_top                     0\n",
       "price (GBP)                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_company_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_company_df.to_csv('Projectdata/cleaned_job_company_pair.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before scaling, we want to:\n",
    "\n",
    "1. Remove `employee_count` and `follower_count` because they may cause multicollinearity with `company_size` and `employee_follower_ratio`.\n",
    "2. Focus our data on U.S. companies only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df = pd.read_csv('Projectdata/cleaned_job_company_pair.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df.drop(columns=['employee_count','follower_count'], inplace=True)\n",
    "\n",
    "# only keep rows with country == 'US'\n",
    "job_df = job_df[job_df['country'] == 'US']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP on text columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_and_reduce_text(df, text_columns, vectorization_method='tfidf', \n",
    "                               reduction_method='pca', n_components=10):\n",
    "\n",
    "    for col in text_columns:\n",
    "        col_text = df[col].apply(preprocess_text)\n",
    "        # combine all text columns\n",
    "        if col == text_columns[0]:\n",
    "            df['preprocessed_text'] = col_text\n",
    "        else:\n",
    "            df['preprocessed_text'] = df['preprocessed_text'] + ' ' + col_text\n",
    "    \n",
    "    # Vectorization\n",
    "    if vectorization_method == 'tfidf':\n",
    "        vectorizer = TfidfVectorizer(max_features=1000)\n",
    "    else:  # count vectorization\n",
    "        vectorizer = CountVectorizer(max_features=1000)\n",
    "    \n",
    "    # Fit and transform text to vector\n",
    "    text_vectors = vectorizer.fit_transform(df['preprocessed_text'])\n",
    "    \n",
    "    # Dimensionality Reduction\n",
    "    if reduction_method == 'pca':\n",
    "        reducer = PCA(n_components=n_components)\n",
    "        # Standardize first for PCA\n",
    "        text_vectors_scaled = StandardScaler().fit_transform(text_vectors.toarray())\n",
    "        reduced_vectors = reducer.fit_transform(text_vectors_scaled)\n",
    "    else:  # Truncated SVD (works well with sparse matrices)\n",
    "        reducer = TruncatedSVD(n_components=n_components)\n",
    "        reduced_vectors = reducer.fit_transform(text_vectors)\n",
    "    \n",
    "    # Create DataFrame with reduced vectors\n",
    "    reduced_df = pd.DataFrame(\n",
    "        reduced_vectors, \n",
    "        columns=[f'{reduction_method}_text_component_{i+1}' for i in range(n_components)]\n",
    "    )\n",
    "    \n",
    "    # Combine original DataFrame with reduced text features\n",
    "    result_df = pd.concat([df, reduced_df], axis=1)\n",
    "    \n",
    "    return result_df, reducer, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_df_vector,_,_ = vectorize_and_reduce_text(job_df, ['skill_name','industry_name','company_name'], n_components=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>company_id</th>\n",
       "      <th>skill_abr</th>\n",
       "      <th>skill_name</th>\n",
       "      <th>industry_id</th>\n",
       "      <th>industry_name</th>\n",
       "      <th>company_size</th>\n",
       "      <th>country</th>\n",
       "      <th>employee_follower_ratio</th>\n",
       "      <th>annual_min_salary</th>\n",
       "      <th>...</th>\n",
       "      <th>company_name</th>\n",
       "      <th>dividend_yield_ttm</th>\n",
       "      <th>is_top</th>\n",
       "      <th>price (GBP)</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>pca_text_component_1</th>\n",
       "      <th>pca_text_component_2</th>\n",
       "      <th>pca_text_component_3</th>\n",
       "      <th>pca_text_component_4</th>\n",
       "      <th>pca_text_component_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>921716</td>\n",
       "      <td>2774458.0</td>\n",
       "      <td>MRKT</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>44</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>0.170991</td>\n",
       "      <td>35360.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Corcoran Sawyer Smith</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>marketing real estate corcoran sawyer smith</td>\n",
       "      <td>-0.368512</td>\n",
       "      <td>0.227145</td>\n",
       "      <td>-0.454321</td>\n",
       "      <td>0.115129</td>\n",
       "      <td>-0.182726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>921716</td>\n",
       "      <td>2774458.0</td>\n",
       "      <td>SALE</td>\n",
       "      <td>Sales</td>\n",
       "      <td>44</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>0.170991</td>\n",
       "      <td>35360.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Corcoran Sawyer Smith</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sales real estate corcoran sawyer smith</td>\n",
       "      <td>-0.379216</td>\n",
       "      <td>0.213018</td>\n",
       "      <td>-0.443585</td>\n",
       "      <td>0.106975</td>\n",
       "      <td>-0.189599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10998357</td>\n",
       "      <td>64896719.0</td>\n",
       "      <td>MNFC</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>32</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>The National Exemplar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>manufacturing restaurants national exemplar</td>\n",
       "      <td>-1.019100</td>\n",
       "      <td>3.282573</td>\n",
       "      <td>2.395577</td>\n",
       "      <td>0.102374</td>\n",
       "      <td>0.123930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10998357</td>\n",
       "      <td>64896719.0</td>\n",
       "      <td>MGMT</td>\n",
       "      <td>Management</td>\n",
       "      <td>32</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>The National Exemplar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>management restaurants national exemplar</td>\n",
       "      <td>-1.000771</td>\n",
       "      <td>3.228462</td>\n",
       "      <td>2.445832</td>\n",
       "      <td>0.061840</td>\n",
       "      <td>0.209240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3899530060</td>\n",
       "      <td>64896719.0</td>\n",
       "      <td>MNFC</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>32</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>The National Exemplar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>manufacturing restaurants national exemplar</td>\n",
       "      <td>-1.019100</td>\n",
       "      <td>3.282573</td>\n",
       "      <td>2.395577</td>\n",
       "      <td>0.102374</td>\n",
       "      <td>0.123930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       job_id  company_id skill_abr     skill_name  industry_id industry_name  \\\n",
       "0      921716   2774458.0      MRKT      Marketing           44   Real Estate   \n",
       "1      921716   2774458.0      SALE          Sales           44   Real Estate   \n",
       "2    10998357  64896719.0      MNFC  Manufacturing           32   Restaurants   \n",
       "3    10998357  64896719.0      MGMT     Management           32   Restaurants   \n",
       "4  3899530060  64896719.0      MNFC  Manufacturing           32   Restaurants   \n",
       "\n",
       "   company_size country  employee_follower_ratio  annual_min_salary  ...  \\\n",
       "0             2      US                 0.170991            35360.0  ...   \n",
       "1             2      US                 0.170991            35360.0  ...   \n",
       "2             1      US                 0.375000            45000.0  ...   \n",
       "3             1      US                 0.375000            45000.0  ...   \n",
       "4             1      US                 0.375000            55000.0  ...   \n",
       "\n",
       "             company_name  dividend_yield_ttm is_top price (GBP)  \\\n",
       "0   Corcoran Sawyer Smith                 0.0  False         0.0   \n",
       "1   Corcoran Sawyer Smith                 0.0  False         0.0   \n",
       "2  The National Exemplar                  0.0  False         0.0   \n",
       "3  The National Exemplar                  0.0  False         0.0   \n",
       "4  The National Exemplar                  0.0  False         0.0   \n",
       "\n",
       "                             preprocessed_text  pca_text_component_1  \\\n",
       "0  marketing real estate corcoran sawyer smith             -0.368512   \n",
       "1      sales real estate corcoran sawyer smith             -0.379216   \n",
       "2  manufacturing restaurants national exemplar             -1.019100   \n",
       "3     management restaurants national exemplar             -1.000771   \n",
       "4  manufacturing restaurants national exemplar             -1.019100   \n",
       "\n",
       "   pca_text_component_2 pca_text_component_3  pca_text_component_4  \\\n",
       "0              0.227145            -0.454321              0.115129   \n",
       "1              0.213018            -0.443585              0.106975   \n",
       "2              3.282573             2.395577              0.102374   \n",
       "3              3.228462             2.445832              0.061840   \n",
       "4              3.282573             2.395577              0.102374   \n",
       "\n",
       "   pca_text_component_5  \n",
       "0             -0.182726  \n",
       "1             -0.189599  \n",
       "2              0.123930  \n",
       "3              0.209240  \n",
       "4              0.123930  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_df_vector.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEmbeddingVectorizer:\n",
    "    def __init__(self, embedding_type='word2vec', vector_size=300):\n",
    "        \"\"\"\n",
    "        Initialize word embedding vectorizer\n",
    "        \n",
    "        Parameters:\n",
    "        embedding_type (str): Type of word embedding \n",
    "            Options: 'word2vec', 'glove', 'fasttext'\n",
    "        vector_size (int): Dimension of word vectors\n",
    "        \"\"\"\n",
    "        self.embedding_type = embedding_type\n",
    "        self.vector_size = vector_size\n",
    "        self.model = self._load_embedding_model()\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    def _load_embedding_model(self):\n",
    "        \"\"\"\n",
    "        Load pre-trained word embedding model\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Mapping of user-friendly names to gensim downloader names\n",
    "            embedding_map = {\n",
    "                'word2vec': 'word2vec-google-news-300',\n",
    "                'glove': 'glove-wiki-gigaword-300',\n",
    "                'fasttext': 'fasttext-wiki-news-subwords-300'\n",
    "            }\n",
    "            \n",
    "            model_name = embedding_map.get(self.embedding_type, 'word2vec-google-news-300')\n",
    "            print(f\"Loading {self.embedding_type} embedding model...\")\n",
    "            return api.load(model_name)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess text for embedding\n",
    "        \n",
    "        Parameters:\n",
    "        text (str): Input text\n",
    "        \n",
    "        Returns:\n",
    "        list: Preprocessed tokens\n",
    "        \"\"\"\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Remove special characters and digits\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and very short words\n",
    "        tokens = [token for token in tokens \n",
    "                  if token not in self.stop_words and len(token) > 2]\n",
    "        \n",
    "        return tokens\n",
    "    \n",
    "    def text_to_vector(self, text, method='mean'):\n",
    "\n",
    "        # Preprocess text\n",
    "        tokens = self.preprocess_text(text)\n",
    "        \n",
    "        # Get word vectors\n",
    "        word_vectors = []\n",
    "        for token in tokens:\n",
    "            try:\n",
    "                # Get vector for each word in the model's vocabulary\n",
    "                word_vectors.append(self.model[token])\n",
    "            except KeyError:\n",
    "                # Skip words not in the vocabulary\n",
    "                continue\n",
    "        \n",
    "        # Handle empty vector case\n",
    "        if not word_vectors:\n",
    "            return np.zeros(self.vector_size)\n",
    "        \n",
    "        # Aggregate word vectors\n",
    "        if method == 'mean':\n",
    "            return np.mean(word_vectors, axis=0)\n",
    "        else:\n",
    "            return np.sum(word_vectors, axis=0)\n",
    "    \n",
    "    def vectorize_dataframe(self, df, text_columns, n_components=10):\n",
    "        # vectorize every column\n",
    "        for col in text_columns:\n",
    "            df[col+'_vector'] = df[col].apply(self.text_to_vector)\n",
    "            # convert to matrix\n",
    "            embedding_matrix = np.vstack(df[col+'_vector'])\n",
    "            # scale the matrix\n",
    "            embedding_matrix = StandardScaler().fit_transform(embedding_matrix)\n",
    "            # apply PCA\n",
    "            pca = PCA(n_components=n_components)\n",
    "            pca_result = pca.fit_transform(embedding_matrix)\n",
    "            # create a new dataframe\n",
    "            pca_df = pd.DataFrame(pca_result, columns=[f'{col}_pca_{i+1}' for i in range(n_components)])\n",
    "            # combine the original dataframe with the pca dataframe\n",
    "            df = pd.concat([df, pca_df], axis=1)\n",
    "        return df, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word2vec embedding model...\n",
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "vectorizer = WordEmbeddingVectorizer(embedding_type='word2vec')\n",
    "job_df_vector, _ = vectorizer.vectorize_dataframe(job_df, ['skill_name','industry_name'], n_components=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>company_id</th>\n",
       "      <th>skill_abr</th>\n",
       "      <th>skill_name</th>\n",
       "      <th>industry_id</th>\n",
       "      <th>industry_name</th>\n",
       "      <th>company_size</th>\n",
       "      <th>country</th>\n",
       "      <th>employee_follower_ratio</th>\n",
       "      <th>annual_min_salary</th>\n",
       "      <th>...</th>\n",
       "      <th>is_top</th>\n",
       "      <th>price (GBP)</th>\n",
       "      <th>skill_name_vector</th>\n",
       "      <th>skill_name_pca_1</th>\n",
       "      <th>skill_name_pca_2</th>\n",
       "      <th>skill_name_pca_3</th>\n",
       "      <th>industry_name_vector</th>\n",
       "      <th>industry_name_pca_1</th>\n",
       "      <th>industry_name_pca_2</th>\n",
       "      <th>industry_name_pca_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>921716</td>\n",
       "      <td>2774458.0</td>\n",
       "      <td>MRKT</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>44</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>0.170991</td>\n",
       "      <td>35360.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.18261719, -0.140625, -0.20410156, -0.136718...</td>\n",
       "      <td>3.080973</td>\n",
       "      <td>4.344913</td>\n",
       "      <td>-5.374780</td>\n",
       "      <td>[0.23144531, 0.0847168, -0.12597656, 0.0641937...</td>\n",
       "      <td>-1.405619</td>\n",
       "      <td>1.455760</td>\n",
       "      <td>-1.803953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>921716</td>\n",
       "      <td>2774458.0</td>\n",
       "      <td>SALE</td>\n",
       "      <td>Sales</td>\n",
       "      <td>44</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>0.170991</td>\n",
       "      <td>35360.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.35742188, -0.110839844, -0.07763672, 0.0834...</td>\n",
       "      <td>13.946016</td>\n",
       "      <td>10.726450</td>\n",
       "      <td>-0.201688</td>\n",
       "      <td>[0.23144531, 0.0847168, -0.12597656, 0.0641937...</td>\n",
       "      <td>-1.405619</td>\n",
       "      <td>1.455760</td>\n",
       "      <td>-1.803953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10998357</td>\n",
       "      <td>64896719.0</td>\n",
       "      <td>MNFC</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>32</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.045166016, -0.013183594, 0.059326172, -0.00...</td>\n",
       "      <td>14.697279</td>\n",
       "      <td>-10.739057</td>\n",
       "      <td>1.994149</td>\n",
       "      <td>[-0.104003906, -0.037841797, 0.08203125, 0.496...</td>\n",
       "      <td>0.782815</td>\n",
       "      <td>3.055054</td>\n",
       "      <td>1.834806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10998357</td>\n",
       "      <td>64896719.0</td>\n",
       "      <td>MGMT</td>\n",
       "      <td>Management</td>\n",
       "      <td>32</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.15332031, 0.103515625, -0.08984375, -0.094...</td>\n",
       "      <td>-5.345903</td>\n",
       "      <td>2.975295</td>\n",
       "      <td>-9.018609</td>\n",
       "      <td>[-0.104003906, -0.037841797, 0.08203125, 0.496...</td>\n",
       "      <td>0.782815</td>\n",
       "      <td>3.055054</td>\n",
       "      <td>1.834806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3899530060</td>\n",
       "      <td>64896719.0</td>\n",
       "      <td>MNFC</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>32</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.045166016, -0.013183594, 0.059326172, -0.00...</td>\n",
       "      <td>14.697279</td>\n",
       "      <td>-10.739057</td>\n",
       "      <td>1.994149</td>\n",
       "      <td>[-0.104003906, -0.037841797, 0.08203125, 0.496...</td>\n",
       "      <td>0.782815</td>\n",
       "      <td>3.055054</td>\n",
       "      <td>1.834806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       job_id  company_id skill_abr     skill_name  industry_id industry_name  \\\n",
       "0      921716   2774458.0      MRKT      Marketing           44   Real Estate   \n",
       "1      921716   2774458.0      SALE          Sales           44   Real Estate   \n",
       "2    10998357  64896719.0      MNFC  Manufacturing           32   Restaurants   \n",
       "3    10998357  64896719.0      MGMT     Management           32   Restaurants   \n",
       "4  3899530060  64896719.0      MNFC  Manufacturing           32   Restaurants   \n",
       "\n",
       "   company_size country  employee_follower_ratio  annual_min_salary  ...  \\\n",
       "0             2      US                 0.170991            35360.0  ...   \n",
       "1             2      US                 0.170991            35360.0  ...   \n",
       "2             1      US                 0.375000            45000.0  ...   \n",
       "3             1      US                 0.375000            45000.0  ...   \n",
       "4             1      US                 0.375000            55000.0  ...   \n",
       "\n",
       "   is_top  price (GBP)                                  skill_name_vector  \\\n",
       "0   False          0.0  [0.18261719, -0.140625, -0.20410156, -0.136718...   \n",
       "1   False          0.0  [0.35742188, -0.110839844, -0.07763672, 0.0834...   \n",
       "2   False          0.0  [0.045166016, -0.013183594, 0.059326172, -0.00...   \n",
       "3   False          0.0  [-0.15332031, 0.103515625, -0.08984375, -0.094...   \n",
       "4   False          0.0  [0.045166016, -0.013183594, 0.059326172, -0.00...   \n",
       "\n",
       "  skill_name_pca_1  skill_name_pca_2  skill_name_pca_3  \\\n",
       "0         3.080973          4.344913         -5.374780   \n",
       "1        13.946016         10.726450         -0.201688   \n",
       "2        14.697279        -10.739057          1.994149   \n",
       "3        -5.345903          2.975295         -9.018609   \n",
       "4        14.697279        -10.739057          1.994149   \n",
       "\n",
       "                                industry_name_vector industry_name_pca_1  \\\n",
       "0  [0.23144531, 0.0847168, -0.12597656, 0.0641937...           -1.405619   \n",
       "1  [0.23144531, 0.0847168, -0.12597656, 0.0641937...           -1.405619   \n",
       "2  [-0.104003906, -0.037841797, 0.08203125, 0.496...            0.782815   \n",
       "3  [-0.104003906, -0.037841797, 0.08203125, 0.496...            0.782815   \n",
       "4  [-0.104003906, -0.037841797, 0.08203125, 0.496...            0.782815   \n",
       "\n",
       "   industry_name_pca_2  industry_name_pca_3  \n",
       "0             1.455760            -1.803953  \n",
       "1             1.455760            -1.803953  \n",
       "2             3.055054             1.834806  \n",
       "3             3.055054             1.834806  \n",
       "4             3.055054             1.834806  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_df_vector.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete two vector columns\n",
    "job_df_vector.drop(columns=['skill_name_vector','industry_name_vector'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df_vector.to_csv('Projectdata/job_data_vectorized_word2vec.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "si618",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
