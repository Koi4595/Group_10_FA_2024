{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[This dataset](https://www.kaggle.com/datasets/patricklford/largest-companies-analysis-worldwide) provides around 10,000 records of the largest companies worldwide. For a job-seeker, Dividend Yield is a key metric to consider when evaluating a company. Dividend Yield is the ratio of the annual dividend per share to the current price per share. So if a job-seeker is offered shares as part of their compensation, they would want to know the Dividend Yield of the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_df = pd.read_csv('Projectdata/Companies_ranked_by_Dividend_Yield.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>dividend_yield_ttm</th>\n",
       "      <th>price (GBP)</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>LianBio</td>\n",
       "      <td>LIAN</td>\n",
       "      <td>300940.0</td>\n",
       "      <td>0.243065</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Richter Gedeon</td>\n",
       "      <td>RIG2.F</td>\n",
       "      <td>150430.0</td>\n",
       "      <td>23.726825</td>\n",
       "      <td>Hungary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Delek Group</td>\n",
       "      <td>DLEKG.TA</td>\n",
       "      <td>117114.0</td>\n",
       "      <td>87.735884</td>\n",
       "      <td>Israel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>LMP Automotive Holdings</td>\n",
       "      <td>LMPX</td>\n",
       "      <td>106250.0</td>\n",
       "      <td>0.121914</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>MBIA</td>\n",
       "      <td>MBI</td>\n",
       "      <td>22346.4</td>\n",
       "      <td>2.727817</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                     Name    Symbol  dividend_yield_ttm  price (GBP)  \\\n",
       "0     1                  LianBio      LIAN            300940.0     0.243065   \n",
       "1     2           Richter Gedeon    RIG2.F            150430.0    23.726825   \n",
       "2     3              Delek Group  DLEKG.TA            117114.0    87.735884   \n",
       "3     4  LMP Automotive Holdings      LMPX            106250.0     0.121914   \n",
       "4     5                     MBIA       MBI             22346.4     2.727817   \n",
       "\n",
       "         country  \n",
       "0  United States  \n",
       "1        Hungary  \n",
       "2         Israel  \n",
       "3  United States  \n",
       "4  United States  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152441    Motion Recruitment\n",
       "282290               TekJobs\n",
       "288707              GOAT USA\n",
       "184550               PepsiCo\n",
       "88269          Russell Tobin\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_df = pd.read_csv('Projectdata/job_company_pair.csv')\n",
    "# randomly select 5 name from job_df\n",
    "job_df['name'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new df that only contains company name in job_df\n",
    "job_df_name = job_df['name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df_name = pd.DataFrame(job_df_name,columns=['company_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Corcoran Sawyer Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The National Exemplar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abrams Fensterman, LLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Downtown Raleigh Alliance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Raw Cereal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                company_name\n",
       "0      Corcoran Sawyer Smith\n",
       "1     The National Exemplar \n",
       "2     Abrams Fensterman, LLP\n",
       "3  Downtown Raleigh Alliance\n",
       "4                 Raw Cereal"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_df_name.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the two dataset are from different sources, we will match the company names using following steps:\n",
    "1. Remove special characters and spaces from the company names in both datasets.\n",
    "2. Convert the company names to lowercase.\n",
    "3. Use the `fuzzywuzzy` library to match the company names.\n",
    "4. If the match score is above a certain threshold, we will consider the two company names to be the same. We will create a new column called `is_top` in the `job_df` dataset to store if there is a match in the `company_df` dataset.\n",
    "5. If `is_top` is False, check if the company name in the `job_df` dataset is a substring of any company name in the `company_df` dataset and vice versa. If it is, we will consider the two company names to be the same and change `is_top` to True.\n",
    "6. If `is_top` is True, we will merge the relevant columns from the `company_df` dataset to the `job_df` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_company_name(name):\n",
    "    \"\"\"\n",
    "    Clean company name by:\n",
    "    1. Removing special characters and spaces\n",
    "    2. Converting to lowercase\n",
    "    \"\"\"\n",
    "    # Convert to string in case of non-string input\n",
    "    name = str(name)\n",
    "    \n",
    "    # Remove special characters and convert to lowercase\n",
    "    cleaned_name = re.sub(r'[^a-zA-Z0-9]', '', name).lower()\n",
    "    \n",
    "    return cleaned_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_longest_substring(s1, s2):\n",
    "    \"\"\"\n",
    "    Find the longest consecutive substring between two strings\n",
    "    \"\"\"\n",
    "    # Remove non-alphanumeric characters\n",
    "    s1 = re.sub(r'[^a-z0-9]', '', s1)\n",
    "    s2 = re.sub(r'[^a-z0-9]', '', s2)\n",
    "    \n",
    "    # Find all consecutive substrings of at least 6 characters\n",
    "    for length in range(min(len(s1), len(s2)), 5, -1):\n",
    "        for i in range(len(s1) - length + 1):\n",
    "            substring = s1[i:i+length]\n",
    "            if substring in s2:\n",
    "                return substring\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_company_names(job_df, company_df, match_threshold=80):\n",
    "    \"\"\"\n",
    "    Match company names between job and company datasets\n",
    "    \n",
    "    Parameters:\n",
    "    - job_df: DataFrame with job listings\n",
    "    - company_df: DataFrame with company information\n",
    "    - match_threshold: Fuzzy matching threshold (default 80)\n",
    "    \n",
    "    Returns:\n",
    "    - Updated job_df with new columns\n",
    "    \"\"\"\n",
    "    # Create copies to avoid modifying original dataframes\n",
    "    job_df = job_df.copy()\n",
    "    company_df = company_df.copy()\n",
    "    \n",
    "    job_df['cleaned_company_name'] = job_df['company_name'].apply(clean_company_name)\n",
    "    company_df['cleaned_company_name'] = company_df['Name'].apply(clean_company_name)\n",
    "    \n",
    "    # Create a dictionary of company names for faster lookup\n",
    "    company_dict = {row['cleaned_company_name']: row for _, row in company_df.iterrows()}\n",
    "    \n",
    "    def find_best_match(job_company):\n",
    "        # Exact match\n",
    "        if job_company in company_dict:\n",
    "            return True, company_dict[job_company]\n",
    "        \n",
    "        # Fuzzy and substring matching\n",
    "        best_match = None\n",
    "        best_score = 0\n",
    "        \n",
    "        for company_name, company_info in company_dict.items():\n",
    "            # Fuzzy ratio match\n",
    "            ratio = fuzz.ratio(job_company, company_name)\n",
    "            \n",
    "            # Substring match bonus\n",
    "            substring_bonus = (job_company in company_name or company_name in job_company)\n",
    "            \n",
    "            # Calculate score with substring bonus\n",
    "            score = ratio + (20 if substring_bonus else 0)\n",
    "            \n",
    "            if score > best_score and score >= match_threshold:\n",
    "                best_score = score\n",
    "                best_match = company_info\n",
    "        \n",
    "        return best_match is not None, best_match\n",
    "    \n",
    "    # Vectorized matching\n",
    "    results = job_df['cleaned_company_name'].apply(find_best_match)\n",
    "    \n",
    "    # Update DataFrame\n",
    "    job_df['is_top'] = results.apply(lambda x: x[0])\n",
    "    \n",
    "    # Merge additional company information for matched companies\n",
    "    def merge_company_info(row, matched_result):\n",
    "        if matched_result[0]:\n",
    "            # Merge relevant columns from company_df\n",
    "            company_info = matched_result[1]\n",
    "            columns_to_merge = ['dividend_yield_ttm','price (GBP)']\n",
    "            for col in columns_to_merge:\n",
    "                if col in company_df.columns and col not in job_df.columns:\n",
    "                    row[col] = company_info[col]\n",
    "        return row\n",
    "    \n",
    "    # Apply merging\n",
    "    job_df = job_df.apply(lambda row: merge_company_info(row, \n",
    "                                       results.loc[row.name]), \n",
    "                           axis=1)\n",
    "    \n",
    "    # Optional: Drop the temporary cleaning column\n",
    "    \n",
    "    return job_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m matched_job_df \u001b[38;5;241m=\u001b[39m \u001b[43mmatch_company_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_df_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompany_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 49\u001b[0m, in \u001b[0;36mmatch_company_names\u001b[0;34m(job_df, company_df, match_threshold)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_match \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, best_match\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Vectorized matching\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mjob_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcleaned_company_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfind_best_match\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Update DataFrame\u001b[39;00m\n\u001b[1;32m     52\u001b[0m job_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_top\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[17], line 34\u001b[0m, in \u001b[0;36mmatch_company_names.<locals>.find_best_match\u001b[0;34m(job_company)\u001b[0m\n\u001b[1;32m     30\u001b[0m best_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m company_name, company_info \u001b[38;5;129;01min\u001b[39;00m company_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# Fuzzy ratio match\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m     ratio \u001b[38;5;241m=\u001b[39m \u001b[43mfuzz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mratio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_company\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompany_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# Substring match bonus\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     substring_bonus \u001b[38;5;241m=\u001b[39m (job_company \u001b[38;5;129;01min\u001b[39;00m company_name \u001b[38;5;129;01mor\u001b[39;00m company_name \u001b[38;5;129;01min\u001b[39;00m job_company)\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/fuzzywuzzy/utils.py:38\u001b[0m, in \u001b[0;36mcheck_for_none.<locals>.decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/fuzzywuzzy/utils.py:29\u001b[0m, in \u001b[0;36mcheck_for_equivalence.<locals>.decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m args[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/fuzzywuzzy/utils.py:47\u001b[0m, in \u001b[0;36mcheck_empty_string.<locals>.decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/fuzzywuzzy/fuzz.py:28\u001b[0m, in \u001b[0;36mratio\u001b[0;34m(s1, s2)\u001b[0m\n\u001b[1;32m     25\u001b[0m s1, s2 \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mmake_type_consistent(s1, s2)\n\u001b[1;32m     27\u001b[0m m \u001b[38;5;241m=\u001b[39m SequenceMatcher(\u001b[38;5;28;01mNone\u001b[39;00m, s1, s2)\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mintr(\u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mratio\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/difflib.py:619\u001b[0m, in \u001b[0;36mSequenceMatcher.ratio\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mratio\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    598\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a measure of the sequences' similarity (float in [0,1]).\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \n\u001b[1;32m    600\u001b[0m \u001b[38;5;124;03m    Where T is the total number of elements in both sequences, and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;124;03m    1.0\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 619\u001b[0m     matches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(triple[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m triple \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_matching_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _calculate_ratio(matches, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb))\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/difflib.py:454\u001b[0m, in \u001b[0;36mSequenceMatcher.get_matching_blocks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m queue:\n\u001b[1;32m    453\u001b[0m     alo, ahi, blo, bhi \u001b[38;5;241m=\u001b[39m queue\u001b[38;5;241m.\u001b[39mpop()\n\u001b[0;32m--> 454\u001b[0m     i, j, k \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_longest_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43malo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mahi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbhi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;66;03m# a[alo:i] vs b[blo:j] unknown\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;66;03m# a[i:i+k] same as b[j:j+k]\u001b[39;00m\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;66;03m# a[i+k:ahi] vs b[j+k:bhi] unknown\u001b[39;00m\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k:   \u001b[38;5;66;03m# if k is 0, there was no matching block\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/difflib.py:379\u001b[0m, in \u001b[0;36mSequenceMatcher.find_longest_match\u001b[0;34m(self, alo, ahi, blo, bhi)\u001b[0m\n\u001b[1;32m    377\u001b[0m j2lenget \u001b[38;5;241m=\u001b[39m j2len\u001b[38;5;241m.\u001b[39mget\n\u001b[1;32m    378\u001b[0m newj2len \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 379\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[43mb2j\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnothing\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;66;03m# a[i] matches b[j]\u001b[39;00m\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m j \u001b[38;5;241m<\u001b[39m blo:\n\u001b[1;32m    382\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "matched_job_df = match_company_names(job_df_name, company_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_job_df.sort_values('is_top', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_job_df.to_csv('Projectdata/matched_companies.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_company_df = pd.read_csv('Projectdata/job_company_pair.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_company_df['cleaned_company_name'] = job_company_df['name'].apply(clean_company_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_company_df = pd.merge(job_company_df, matched_job_df, how='left', on='cleaned_company_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_company_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_company_df.drop(columns=['cleaned_company_name','name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_company_df.to_csv('Projectdata/matched_job_company_pair.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df = pd.read_csv('Projectdata/cleaned_job_company_pair.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_and_reduce_text(df, text_columns, vectorization_method='tfidf', \n",
    "                               reduction_method='pca', n_components=10):\n",
    "\n",
    "    for col in text_columns:\n",
    "        col_text = df[col].apply(preprocess_text)\n",
    "        # combine all text columns\n",
    "        if col == text_columns[0]:\n",
    "            df['preprocessed_text'] = col_text\n",
    "        else:\n",
    "            df['preprocessed_text'] = df['preprocessed_text'] + ' ' + col_text\n",
    "    \n",
    "    # Vectorization\n",
    "    if vectorization_method == 'tfidf':\n",
    "        vectorizer = TfidfVectorizer(max_features=1000)\n",
    "    else:  # count vectorization\n",
    "        vectorizer = CountVectorizer(max_features=1000)\n",
    "    \n",
    "    # Fit and transform text to vector\n",
    "    text_vectors = vectorizer.fit_transform(df['preprocessed_text'])\n",
    "    \n",
    "    # Dimensionality Reduction\n",
    "    if reduction_method == 'pca':\n",
    "        reducer = PCA(n_components=n_components)\n",
    "        # Standardize first for PCA\n",
    "        text_vectors_scaled = StandardScaler().fit_transform(text_vectors.toarray())\n",
    "        reduced_vectors = reducer.fit_transform(text_vectors_scaled)\n",
    "    else:  # Truncated SVD (works well with sparse matrices)\n",
    "        reducer = TruncatedSVD(n_components=n_components)\n",
    "        reduced_vectors = reducer.fit_transform(text_vectors)\n",
    "    \n",
    "    # Create DataFrame with reduced vectors\n",
    "    reduced_df = pd.DataFrame(\n",
    "        reduced_vectors, \n",
    "        columns=[f'{reduction_method}_text_component_{i+1}' for i in range(n_components)]\n",
    "    )\n",
    "    \n",
    "    # Combine original DataFrame with reduced text features\n",
    "    result_df = pd.concat([df, reduced_df], axis=1)\n",
    "    \n",
    "    return result_df, reducer, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df_vector,_,_ = vectorize_and_reduce_text(job_df, ['skill_name','industry_name','company_name'], n_components=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>company_id</th>\n",
       "      <th>skill_abr</th>\n",
       "      <th>skill_name</th>\n",
       "      <th>industry_id</th>\n",
       "      <th>industry_name</th>\n",
       "      <th>company_size</th>\n",
       "      <th>country</th>\n",
       "      <th>employee_count</th>\n",
       "      <th>follower_count</th>\n",
       "      <th>...</th>\n",
       "      <th>price (GBP)</th>\n",
       "      <th>preprocessed_skill_name</th>\n",
       "      <th>preprocessed_industry_name</th>\n",
       "      <th>preprocessed_company_name</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>pca_text_component_1</th>\n",
       "      <th>pca_text_component_2</th>\n",
       "      <th>pca_text_component_3</th>\n",
       "      <th>pca_text_component_4</th>\n",
       "      <th>pca_text_component_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>921716</td>\n",
       "      <td>2774458.0</td>\n",
       "      <td>MRKT</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>44</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>402</td>\n",
       "      <td>2351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>marketing</td>\n",
       "      <td>real estate</td>\n",
       "      <td>corcoran sawyer smith</td>\n",
       "      <td>marketing real estate corcoran sawyer smith</td>\n",
       "      <td>-0.368512</td>\n",
       "      <td>0.227145</td>\n",
       "      <td>-0.454321</td>\n",
       "      <td>0.115129</td>\n",
       "      <td>-0.182726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>921716</td>\n",
       "      <td>2774458.0</td>\n",
       "      <td>SALE</td>\n",
       "      <td>Sales</td>\n",
       "      <td>44</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>402</td>\n",
       "      <td>2351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sales</td>\n",
       "      <td>real estate</td>\n",
       "      <td>corcoran sawyer smith</td>\n",
       "      <td>sales real estate corcoran sawyer smith</td>\n",
       "      <td>-0.379216</td>\n",
       "      <td>0.213018</td>\n",
       "      <td>-0.443585</td>\n",
       "      <td>0.106975</td>\n",
       "      <td>-0.189599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10998357</td>\n",
       "      <td>64896719.0</td>\n",
       "      <td>MNFC</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>32</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>15</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>manufacturing</td>\n",
       "      <td>restaurants</td>\n",
       "      <td>national exemplar</td>\n",
       "      <td>manufacturing restaurants national exemplar</td>\n",
       "      <td>-1.019100</td>\n",
       "      <td>3.282573</td>\n",
       "      <td>2.395577</td>\n",
       "      <td>0.102374</td>\n",
       "      <td>0.123930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10998357</td>\n",
       "      <td>64896719.0</td>\n",
       "      <td>MGMT</td>\n",
       "      <td>Management</td>\n",
       "      <td>32</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>15</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>management</td>\n",
       "      <td>restaurants</td>\n",
       "      <td>national exemplar</td>\n",
       "      <td>management restaurants national exemplar</td>\n",
       "      <td>-1.000771</td>\n",
       "      <td>3.228462</td>\n",
       "      <td>2.445832</td>\n",
       "      <td>0.061840</td>\n",
       "      <td>0.209240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3899530060</td>\n",
       "      <td>64896719.0</td>\n",
       "      <td>MNFC</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>32</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>15</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>manufacturing</td>\n",
       "      <td>restaurants</td>\n",
       "      <td>national exemplar</td>\n",
       "      <td>manufacturing restaurants national exemplar</td>\n",
       "      <td>-1.019100</td>\n",
       "      <td>3.282573</td>\n",
       "      <td>2.395577</td>\n",
       "      <td>0.102374</td>\n",
       "      <td>0.123930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       job_id  company_id skill_abr     skill_name  industry_id industry_name  \\\n",
       "0      921716   2774458.0      MRKT      Marketing           44   Real Estate   \n",
       "1      921716   2774458.0      SALE          Sales           44   Real Estate   \n",
       "2    10998357  64896719.0      MNFC  Manufacturing           32   Restaurants   \n",
       "3    10998357  64896719.0      MGMT     Management           32   Restaurants   \n",
       "4  3899530060  64896719.0      MNFC  Manufacturing           32   Restaurants   \n",
       "\n",
       "   company_size country  employee_count  follower_count  ...  price (GBP)  \\\n",
       "0             2      US             402            2351  ...          0.0   \n",
       "1             2      US             402            2351  ...          0.0   \n",
       "2             1      US              15              40  ...          0.0   \n",
       "3             1      US              15              40  ...          0.0   \n",
       "4             1      US              15              40  ...          0.0   \n",
       "\n",
       "   preprocessed_skill_name  preprocessed_industry_name  \\\n",
       "0                marketing                 real estate   \n",
       "1                    sales                 real estate   \n",
       "2            manufacturing                 restaurants   \n",
       "3               management                 restaurants   \n",
       "4            manufacturing                 restaurants   \n",
       "\n",
       "   preprocessed_company_name                            preprocessed_text  \\\n",
       "0      corcoran sawyer smith  marketing real estate corcoran sawyer smith   \n",
       "1      corcoran sawyer smith      sales real estate corcoran sawyer smith   \n",
       "2          national exemplar  manufacturing restaurants national exemplar   \n",
       "3          national exemplar     management restaurants national exemplar   \n",
       "4          national exemplar  manufacturing restaurants national exemplar   \n",
       "\n",
       "  pca_text_component_1  pca_text_component_2  pca_text_component_3  \\\n",
       "0            -0.368512              0.227145             -0.454321   \n",
       "1            -0.379216              0.213018             -0.443585   \n",
       "2            -1.019100              3.282573              2.395577   \n",
       "3            -1.000771              3.228462              2.445832   \n",
       "4            -1.019100              3.282573              2.395577   \n",
       "\n",
       "   pca_text_component_4 pca_text_component_5  \n",
       "0              0.115129            -0.182726  \n",
       "1              0.106975            -0.189599  \n",
       "2              0.102374             0.123930  \n",
       "3              0.061840             0.209240  \n",
       "4              0.102374             0.123930  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_df_vector.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df_vector.to_csv('Projectdata/job_data_vectorized.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering/Classification Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model test and validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
