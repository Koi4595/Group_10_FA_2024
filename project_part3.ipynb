{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[This dataset](https://www.kaggle.com/datasets/patricklford/largest-companies-analysis-worldwide) provides around 10,000 records of the largest companies worldwide. For a job-seeker, Dividend Yield is a key metric to consider when evaluating a company. Dividend Yield is the ratio of the annual dividend per share to the current price per share. So if a job-seeker is offered shares as part of their compensation, they would want to know the Dividend Yield of the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/si618/lib/python3.12/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_df = pd.read_csv('Projectdata/Companies_ranked_by_Dividend_Yield.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df = pd.read_csv('Projectdata/job_company_pair.csv')\n",
    "# randomly select 5 name from job_df\n",
    "job_df['name'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new df that only contains company name in job_df\n",
    "job_df_name = job_df['name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df_name = pd.DataFrame(job_df_name,columns=['company_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df_name.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the two dataset are from different sources, we will match the company names using following steps:\n",
    "1. Remove special characters and spaces from the company names in both datasets.\n",
    "2. Convert the company names to lowercase.\n",
    "3. Use the `fuzzywuzzy` library to match the company names.\n",
    "4. If the match score is above a certain threshold, we will consider the two company names to be the same. We will create a new column called `is_top` in the `job_df` dataset to store if there is a match in the `company_df` dataset.\n",
    "5. If `is_top` is False, check if the company name in the `job_df` dataset is a substring of any company name in the `company_df` dataset and vice versa. If it is, we will consider the two company names to be the same and change `is_top` to True.\n",
    "6. If `is_top` is True, we will merge the relevant columns from the `company_df` dataset to the `job_df` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_company_name(name):\n",
    "    \"\"\"\n",
    "    Clean company name by:\n",
    "    1. Removing special characters and spaces\n",
    "    2. Converting to lowercase\n",
    "    \"\"\"\n",
    "    # Convert to string in case of non-string input\n",
    "    name = str(name)\n",
    "    \n",
    "    # Remove special characters and convert to lowercase\n",
    "    cleaned_name = re.sub(r'[^a-zA-Z0-9]', '', name).lower()\n",
    "    \n",
    "    return cleaned_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_longest_substring(s1, s2):\n",
    "    \"\"\"\n",
    "    Find the longest consecutive substring between two strings\n",
    "    \"\"\"\n",
    "    # Remove non-alphanumeric characters\n",
    "    s1 = re.sub(r'[^a-z0-9]', '', s1)\n",
    "    s2 = re.sub(r'[^a-z0-9]', '', s2)\n",
    "    \n",
    "    # Find all consecutive substrings of at least 6 characters\n",
    "    for length in range(min(len(s1), len(s2)), 5, -1):\n",
    "        for i in range(len(s1) - length + 1):\n",
    "            substring = s1[i:i+length]\n",
    "            if substring in s2:\n",
    "                return substring\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_company_names(job_df, company_df, match_threshold=80):\n",
    "    \"\"\"\n",
    "    Match company names between job and company datasets\n",
    "    \n",
    "    Parameters:\n",
    "    - job_df: DataFrame with job listings\n",
    "    - company_df: DataFrame with company information\n",
    "    - match_threshold: Fuzzy matching threshold (default 80)\n",
    "    \n",
    "    Returns:\n",
    "    - Updated job_df with new columns\n",
    "    \"\"\"\n",
    "    # Create copies to avoid modifying original dataframes\n",
    "    job_df = job_df.copy()\n",
    "    company_df = company_df.copy()\n",
    "    \n",
    "    job_df['cleaned_company_name'] = job_df['company_name'].apply(clean_company_name)\n",
    "    company_df['cleaned_company_name'] = company_df['Name'].apply(clean_company_name)\n",
    "    \n",
    "    # Create a dictionary of company names for faster lookup\n",
    "    company_dict = {row['cleaned_company_name']: row for _, row in company_df.iterrows()}\n",
    "    \n",
    "    def find_best_match(job_company):\n",
    "        # Exact match\n",
    "        if job_company in company_dict:\n",
    "            return True, company_dict[job_company]\n",
    "        \n",
    "        # Fuzzy and substring matching\n",
    "        best_match = None\n",
    "        best_score = 0\n",
    "        \n",
    "        for company_name, company_info in company_dict.items():\n",
    "            # Fuzzy ratio match\n",
    "            ratio = fuzz.ratio(job_company, company_name)\n",
    "            \n",
    "            # Substring match bonus\n",
    "            substring_bonus = (job_company in company_name or company_name in job_company)\n",
    "            \n",
    "            # Calculate score with substring bonus\n",
    "            score = ratio + (20 if substring_bonus else 0)\n",
    "            \n",
    "            if score > best_score and score >= match_threshold:\n",
    "                best_score = score\n",
    "                best_match = company_info\n",
    "        \n",
    "        return best_match is not None, best_match\n",
    "    \n",
    "    # Vectorized matching\n",
    "    results = job_df['cleaned_company_name'].apply(find_best_match)\n",
    "    \n",
    "    # Update DataFrame\n",
    "    job_df['is_top'] = results.apply(lambda x: x[0])\n",
    "    \n",
    "    # Merge additional company information for matched companies\n",
    "    def merge_company_info(row, matched_result):\n",
    "        if matched_result[0]:\n",
    "            # Merge relevant columns from company_df\n",
    "            company_info = matched_result[1]\n",
    "            columns_to_merge = ['dividend_yield_ttm','price (GBP)']\n",
    "            for col in columns_to_merge:\n",
    "                if col in company_df.columns and col not in job_df.columns:\n",
    "                    row[col] = company_info[col]\n",
    "        return row\n",
    "    \n",
    "    # Apply merging\n",
    "    job_df = job_df.apply(lambda row: merge_company_info(row, \n",
    "                                       results.loc[row.name]), \n",
    "                           axis=1)\n",
    "    \n",
    "    # Optional: Drop the temporary cleaning column\n",
    "    \n",
    "    return job_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_job_df = match_company_names(job_df_name, company_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_job_df.sort_values('is_top', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_job_df.to_csv('Projectdata/matched_companies.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_company_df = pd.read_csv('Projectdata/job_company_pair.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_company_df['cleaned_company_name'] = job_company_df['name'].apply(clean_company_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_company_df = pd.merge(job_company_df, matched_job_df, how='left', on='cleaned_company_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_company_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_company_df.drop(columns=['cleaned_company_name','name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_company_df.to_csv('Projectdata/matched_job_company_pair.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df = pd.read_csv('Projectdata/cleaned_job_company_pair.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_and_reduce_text(df, text_columns, vectorization_method='tfidf', \n",
    "                               reduction_method='pca', n_components=10):\n",
    "\n",
    "    for col in text_columns:\n",
    "        col_text = df[col].apply(preprocess_text)\n",
    "        # combine all text columns\n",
    "        if col == text_columns[0]:\n",
    "            df['preprocessed_text'] = col_text\n",
    "        else:\n",
    "            df['preprocessed_text'] = df['preprocessed_text'] + ' ' + col_text\n",
    "    \n",
    "    # Vectorization\n",
    "    if vectorization_method == 'tfidf':\n",
    "        vectorizer = TfidfVectorizer(max_features=1000)\n",
    "    else:  # count vectorization\n",
    "        vectorizer = CountVectorizer(max_features=1000)\n",
    "    \n",
    "    # Fit and transform text to vector\n",
    "    text_vectors = vectorizer.fit_transform(df['preprocessed_text'])\n",
    "    \n",
    "    # Dimensionality Reduction\n",
    "    if reduction_method == 'pca':\n",
    "        reducer = PCA(n_components=n_components)\n",
    "        # Standardize first for PCA\n",
    "        text_vectors_scaled = StandardScaler().fit_transform(text_vectors.toarray())\n",
    "        reduced_vectors = reducer.fit_transform(text_vectors_scaled)\n",
    "    else:  # Truncated SVD (works well with sparse matrices)\n",
    "        reducer = TruncatedSVD(n_components=n_components)\n",
    "        reduced_vectors = reducer.fit_transform(text_vectors)\n",
    "    \n",
    "    # Create DataFrame with reduced vectors\n",
    "    reduced_df = pd.DataFrame(\n",
    "        reduced_vectors, \n",
    "        columns=[f'{reduction_method}_text_component_{i+1}' for i in range(n_components)]\n",
    "    )\n",
    "    \n",
    "    # Combine original DataFrame with reduced text features\n",
    "    result_df = pd.concat([df, reduced_df], axis=1)\n",
    "    \n",
    "    return result_df, reducer, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df_vector,_,_ = vectorize_and_reduce_text(job_df, ['skill_name','industry_name','company_name'], n_components=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>company_id</th>\n",
       "      <th>skill_abr</th>\n",
       "      <th>skill_name</th>\n",
       "      <th>industry_id</th>\n",
       "      <th>industry_name</th>\n",
       "      <th>company_size</th>\n",
       "      <th>country</th>\n",
       "      <th>employee_count</th>\n",
       "      <th>follower_count</th>\n",
       "      <th>...</th>\n",
       "      <th>price (GBP)</th>\n",
       "      <th>preprocessed_skill_name</th>\n",
       "      <th>preprocessed_industry_name</th>\n",
       "      <th>preprocessed_company_name</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>pca_text_component_1</th>\n",
       "      <th>pca_text_component_2</th>\n",
       "      <th>pca_text_component_3</th>\n",
       "      <th>pca_text_component_4</th>\n",
       "      <th>pca_text_component_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>921716</td>\n",
       "      <td>2774458.0</td>\n",
       "      <td>MRKT</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>44</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>402</td>\n",
       "      <td>2351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>marketing</td>\n",
       "      <td>real estate</td>\n",
       "      <td>corcoran sawyer smith</td>\n",
       "      <td>marketing real estate corcoran sawyer smith</td>\n",
       "      <td>-0.368512</td>\n",
       "      <td>0.227145</td>\n",
       "      <td>-0.454321</td>\n",
       "      <td>0.115129</td>\n",
       "      <td>-0.182726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>921716</td>\n",
       "      <td>2774458.0</td>\n",
       "      <td>SALE</td>\n",
       "      <td>Sales</td>\n",
       "      <td>44</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>402</td>\n",
       "      <td>2351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sales</td>\n",
       "      <td>real estate</td>\n",
       "      <td>corcoran sawyer smith</td>\n",
       "      <td>sales real estate corcoran sawyer smith</td>\n",
       "      <td>-0.379216</td>\n",
       "      <td>0.213018</td>\n",
       "      <td>-0.443585</td>\n",
       "      <td>0.106975</td>\n",
       "      <td>-0.189599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10998357</td>\n",
       "      <td>64896719.0</td>\n",
       "      <td>MNFC</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>32</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>15</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>manufacturing</td>\n",
       "      <td>restaurants</td>\n",
       "      <td>national exemplar</td>\n",
       "      <td>manufacturing restaurants national exemplar</td>\n",
       "      <td>-1.019100</td>\n",
       "      <td>3.282573</td>\n",
       "      <td>2.395577</td>\n",
       "      <td>0.102374</td>\n",
       "      <td>0.123930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10998357</td>\n",
       "      <td>64896719.0</td>\n",
       "      <td>MGMT</td>\n",
       "      <td>Management</td>\n",
       "      <td>32</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>15</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>management</td>\n",
       "      <td>restaurants</td>\n",
       "      <td>national exemplar</td>\n",
       "      <td>management restaurants national exemplar</td>\n",
       "      <td>-1.000771</td>\n",
       "      <td>3.228462</td>\n",
       "      <td>2.445832</td>\n",
       "      <td>0.061840</td>\n",
       "      <td>0.209240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3899530060</td>\n",
       "      <td>64896719.0</td>\n",
       "      <td>MNFC</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>32</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>15</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>manufacturing</td>\n",
       "      <td>restaurants</td>\n",
       "      <td>national exemplar</td>\n",
       "      <td>manufacturing restaurants national exemplar</td>\n",
       "      <td>-1.019100</td>\n",
       "      <td>3.282573</td>\n",
       "      <td>2.395577</td>\n",
       "      <td>0.102374</td>\n",
       "      <td>0.123930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       job_id  company_id skill_abr     skill_name  industry_id industry_name  \\\n",
       "0      921716   2774458.0      MRKT      Marketing           44   Real Estate   \n",
       "1      921716   2774458.0      SALE          Sales           44   Real Estate   \n",
       "2    10998357  64896719.0      MNFC  Manufacturing           32   Restaurants   \n",
       "3    10998357  64896719.0      MGMT     Management           32   Restaurants   \n",
       "4  3899530060  64896719.0      MNFC  Manufacturing           32   Restaurants   \n",
       "\n",
       "   company_size country  employee_count  follower_count  ...  price (GBP)  \\\n",
       "0             2      US             402            2351  ...          0.0   \n",
       "1             2      US             402            2351  ...          0.0   \n",
       "2             1      US              15              40  ...          0.0   \n",
       "3             1      US              15              40  ...          0.0   \n",
       "4             1      US              15              40  ...          0.0   \n",
       "\n",
       "   preprocessed_skill_name  preprocessed_industry_name  \\\n",
       "0                marketing                 real estate   \n",
       "1                    sales                 real estate   \n",
       "2            manufacturing                 restaurants   \n",
       "3               management                 restaurants   \n",
       "4            manufacturing                 restaurants   \n",
       "\n",
       "   preprocessed_company_name                            preprocessed_text  \\\n",
       "0      corcoran sawyer smith  marketing real estate corcoran sawyer smith   \n",
       "1      corcoran sawyer smith      sales real estate corcoran sawyer smith   \n",
       "2          national exemplar  manufacturing restaurants national exemplar   \n",
       "3          national exemplar     management restaurants national exemplar   \n",
       "4          national exemplar  manufacturing restaurants national exemplar   \n",
       "\n",
       "  pca_text_component_1  pca_text_component_2  pca_text_component_3  \\\n",
       "0            -0.368512              0.227145             -0.454321   \n",
       "1            -0.379216              0.213018             -0.443585   \n",
       "2            -1.019100              3.282573              2.395577   \n",
       "3            -1.000771              3.228462              2.445832   \n",
       "4            -1.019100              3.282573              2.395577   \n",
       "\n",
       "   pca_text_component_4 pca_text_component_5  \n",
       "0              0.115129            -0.182726  \n",
       "1              0.106975            -0.189599  \n",
       "2              0.102374             0.123930  \n",
       "3              0.061840             0.209240  \n",
       "4              0.102374             0.123930  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_df_vector.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df_vector.to_csv('Projectdata/job_data_vectorized.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "si618",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
